{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFSzKojHw+fQeS7hL50Lrs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmastrianni13/datalab-notebooks/blob/master/data-space/sankofa/dated/twitter_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlvuUDMcvUuy",
        "colab_type": "text"
      },
      "source": [
        "Basic clean wrapper class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG35If8St89c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class BasicClean(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self, X_column):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.X_column = X_column\n",
        "        \n",
        "\n",
        "    def fit(self, X, y = None):\n",
        "        return self\n",
        "\n",
        "\n",
        "    def transform(self, X, y = None):\n",
        "        \n",
        "        X_column = self.X_column\n",
        "        \n",
        "        df = X.copy()\n",
        "   \n",
        "        # Convert unicode to ascii\n",
        "        import unicodedata\n",
        "\n",
        "        df[X_column] = df[X_column].apply(lambda x: unicodedata.normalize('NFKD', x).encode('ascii', 'ignore').decode())    \n",
        "    \n",
        "        # Convert all text to lowercase\n",
        "        df[X_column] = df[X_column].str.lower()\n",
        "        \n",
        "        # Correct spelling mistakes\n",
        "        ''' need code to correct spelling mistakes '''\n",
        "        \n",
        "        #Replace repeating characters of 3+ repeats to 2 (ie 'bbbb' -> 'b')\n",
        "        \n",
        "        min_threshold_rep = 3\n",
        "        \n",
        "        df[X_column]= df[X_column].str.replace(r'(\\w)\\1{%d,}'%(min_threshold_rep-1), r'\\1')\n",
        "        \n",
        "        # Remove noise:\n",
        "        #    hyperlinks\n",
        "        df[X_column] = df[X_column].str.replace(r\"http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+\", \"\", regex = True)\n",
        "                \n",
        "        #    punctuation - This needs to be updated so smilies are not affected\n",
        "        import string\n",
        "       \n",
        "        df[X_column] = df[X_column].str.replace('[{}]'.format(string.punctuation), '')\n",
        "\n",
        "        #Remove stop words\n",
        "        ''' build in functionality to support custom wordbank stopwords and nltk stopwords '''\n",
        "        from sklearn.feature_extraction import stop_words\n",
        "\n",
        "    \n",
        "        stop = stop_words.ENGLISH_STOP_WORDS\n",
        "    \n",
        "        df[X_column] = df[X_column].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))\n",
        "        \n",
        "        return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djIi6dj0vc8z",
        "colab_type": "text"
      },
      "source": [
        "Stemming wrapper class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC5iNSNqvcSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class LangStemmer(BaseEstimator, TransformerMixin):\n",
        "    '''\n",
        "        Convert words to their base form via stemming\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, X_column):\n",
        "        super().__init__()\n",
        "\n",
        "        self.X_column = X_column\n",
        "\n",
        "    def fit(self, X, y = None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y = None):\n",
        "        \n",
        "        X_column = self.X_column\n",
        "        \n",
        "        df = X.copy()\n",
        "           \n",
        "        from nltk.stem import PorterStemmer\n",
        "        \n",
        "        ps = PorterStemmer()\n",
        "    \n",
        "        df[X_column] = df[X_column].apply(lambda x: ' '.join([ps.stem(word) for word in x.split()]))\n",
        "        \n",
        "        return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ucKi8Vvhqb",
        "colab_type": "text"
      },
      "source": [
        "Lemmatization wrapper class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cj4DtoovkKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class LangLemmer(BaseEstimator, TransformerMixin):\n",
        "    '''\n",
        "        Convert words to their base form via lemmatization\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, X_column):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.X_column = X_column\n",
        "\n",
        "    def fit(self, X, y = None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y = None):\n",
        "        \n",
        "        X_column = self.X_column\n",
        "        \n",
        "        df = X.copy()\n",
        "\n",
        "        from nltk.stem import WordNetLemmatizer\n",
        "        \n",
        "        wnl = WordNetLemmatizer()\n",
        "    \n",
        "        df[X_column] = df[X_column].apply(lambda x: ' '.join([wnl.lemmatize(word) for word in x.split()]))\n",
        "       \n",
        "        return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDh8MVVmvpnX",
        "colab_type": "text"
      },
      "source": [
        "Count Vectorizer wrapper class\n",
        "\n",
        "Notes: Sometime the transform method returns a dataframe where the target column is itself a dataframe (instead of a series).  When this occurs, processing halts since we no longer have access to any series methods such value_counts()\n",
        "\n",
        "This can be checked by returning the type on the dataframe's target column\n",
        "\n",
        "Example of useable dataframe returned:\n",
        "type(lemm_v_tweets.target)\n",
        "\n",
        "Out[13]: pandas.core.series.Series\n",
        "\n",
        "Example of unuseable dataframe returned:\n",
        "type(lemm_v_tweets.target)\n",
        "\n",
        "Out[19]: pandas.core.frame.DataFrame\n",
        "\n",
        "Future updates - use fit_transform method in this wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1y66AzPvmSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVM-8c-jvoFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}